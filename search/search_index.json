{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Singtel Data Science Assessment","text":"<p>Technical Take-Home Test \u2013 Senior Data Scientist</p> <p>This take-home assessment demonstrates skills in building AI-powered agent workflows, predictive modules and integrate software components using modern tools and frameworks.</p>"},{"location":"01_assignment/","title":"Singtel Data Science Assessment","text":"<p>Technical Take-Home Test \u2013 Senior Data Scientist</p> <p>Thanks for your interest in the role! This take-home assessment will allow you to demonstrate your skills in building AI-powered agent workflows, predictive modules and integrate software components using modern tools and frameworks.</p>"},{"location":"01_assignment/#submission-deadline","title":"Submission Deadline","text":"<p>Please submit your completed assignment by 14th July 2025. We will take stock of your submitted repository for evaluation at this point. After that, any further commits will not be part of the evaluation but can be considered as interview preparations.</p>"},{"location":"01_assignment/#reference-repository","title":"Reference Repository","text":"<p>Your tasks will be based on the following OpenAI CS Agents Demo repository: OpenAI CS Agents Demo</p> <p>Please fork this repository and use it as the foundation for completing the tasks. Feel free to swap framework or model providers as you see fit. (Ps: Our team uses Langchain/Langgraph and will be happy to review code written in these frameworks)</p>"},{"location":"01_assignment/#expected-deliverable-artifacts","title":"Expected Deliverable Artifacts","text":"<p>Submit the following:</p> <ul> <li>Link to your GitHub fork. Do ensure that the repository is accessible! The repo should contain the following</li> <li>Artifacts for your completed tasks (code and documentation)</li> <li>Instructions to run your code \u2013 you are recommended to make the application easily deployable to a service such as Replit, so that we can easily spin up an instance to check out your application.</li> <li>PDF or Markdown document with your Integration Strategy write-up. </li> <li>Optional Screenshots or access details for your bonus dashboard/logging solution.</li> </ul>"},{"location":"01_assignment/#further-notes","title":"Further Notes","text":"<ul> <li>You are encouraged to use AI tools (e.g., ChatGPT, GitHub Copilot, Claude, Gemini) to help accelerate your delivery. Ensure you understand the generated code and document your reasoning clearly. Your grasp and thoughtful integration of AI-generated content will be evaluated.</li> <li>This assessment is meant to be time-scoped, in respect of your busy schedules. As a guideline the tasks above should take no more than 10 hours of focused time.</li> </ul> <p>All the best! We look forward to reviewing your submission.</p>"},{"location":"01_assignment/#tasks","title":"Tasks","text":"id status task 01 open Custom Agent and Tool 02 open Retrieval-Augmented Generation (RAG) 03 open Integration Strategy and Approach (Write-up) 04 open Optional Bonus Task"},{"location":"01_assignment/#open-task-1-custom-agent-and-tool","title":"(open) Task 1: Custom Agent and Tool","text":"<p>Implement a new custom agent and at least one custom tool suitable for a telecommunications use case. Possible examples include:</p> <ul> <li>Telco Products/Roaming plan recommendation engine (preferred, due to immediate relevance to JD)</li> <li>Billing dispute parsing and categorization (good to have)</li> <li>Data usage history check (good to have)</li> </ul> <p>Mocked data is allowed to enable the tool\u2019s demonstration. To keep within a time bound, please describe some of the approaches you have planned and would have utilised, if given sufficient time.</p> <p>Clearly document:</p> <ul> <li>The specific business problem your custom tool addresses.</li> <li>Integration method between your tool and the agent.</li> </ul>"},{"location":"01_assignment/#open-task-2-retrieval-augmented-generation-rag","title":"(open) Task 2: Retrieval-Augmented Generation (RAG)","text":"<p>Implement a basic RAG pipeline to ground your agent's responses. You may use:</p> <ul> <li>A small document collection</li> <li>Mocked/Generated telco knowledge base </li> <li>Public web available data</li> </ul> <p>Clearly indicate in your response logs when retrieved information is being utilized. Whilst there is limited opportunity to extensively fine-tune, do state some your proposed techniques/approaches to improve the RAG pipeline</p>"},{"location":"01_assignment/#open-task-3-integration-strategy-and-approach-write-up","title":"(open) Task 3: Integration Strategy and Approach (Write-up)","text":"<p>Provide a concise (~400 words) strategy document outlining:</p> <ul> <li>Possible deployment methods for your agent in an enterprise telco environment (e.g., WhatsApp, Microsoft Teams, web portal).</li> <li>Anticipated practical integration challenges (authentication, latency, UI design, scalability).</li> <li>Metrics to evaluate agent performance and value in a production environment.</li> </ul>"},{"location":"01_assignment/#open-task-4-optional-bonus-task","title":"(open) Task 4: Optional Bonus Task","text":"<p>Create a simple usage dashboard or logging mechanism demonstrating:</p> <ul> <li>Total user queries handled</li> <li>Breakdown of tool usage frequency</li> <li>Retrieval hit/miss analytics</li> </ul> <p>Feel free to use lightweight frameworks like Streamlit, Gradio, NiceGUI, Flask, or FastAPI.</p>"},{"location":"02_project/","title":"Project information","text":"Github repository taylorhickem/singtel-ds-assessment Documentation Github page: Singtel Data Science Assessment"},{"location":"04_guidelines/","title":"Guidelines","text":""},{"location":"04_guidelines/#submission-deadline","title":"Submission Deadline","text":"<p>Please submit your completed assignment by 14th July 2025. We will take stock of your submitted repository for evaluation at this point. After that, any further commits will not be part of the evaluation but can be considered as interview preparations.</p>"},{"location":"04_guidelines/#reference-repository","title":"Reference Repository","text":"<p>Your tasks will be based on the following OpenAI CS Agents Demo repository: OpenAI CS Agents Demo</p> <p>Please fork this repository and use it as the foundation for completing the tasks. Feel free to swap framework or model providers as you see fit. (Ps: Our team uses Langchain/Langgraph and will be happy to review code written in these frameworks)</p>"},{"location":"04_guidelines/#expected-deliverable-artifacts","title":"Expected Deliverable Artifacts","text":"<p>Submit the following:</p> <ul> <li>Link to your GitHub fork. Do ensure that the repository is accessible! The repo should contain the following</li> <li>Artifacts for your completed tasks (code and documentation)</li> <li>Instructions to run your code \u2013 you are recommended to make the application easily deployable to a service such as Replit, so that we can easily spin up an instance to check out your application.</li> <li>PDF or Markdown document with your Integration Strategy write-up. </li> <li>Optional Screenshots or access details for your bonus dashboard/logging solution.</li> </ul>"},{"location":"04_guidelines/#further-notes","title":"Further Notes","text":"<ul> <li>You are encouraged to use AI tools (e.g., ChatGPT, GitHub Copilot, Claude, Gemini) to help accelerate your delivery. Ensure you understand the generated code and document your reasoning clearly. Your grasp and thoughtful integration of AI-generated content will be evaluated.</li> <li>This assessment is meant to be time-scoped, in respect of your busy schedules. As a guideline the tasks above should take no more than 10 hours of focused time.</li> </ul>"},{"location":"tasks/0301_custom_agent/","title":"Custom Agent and Tool","text":"<p>Implement a new custom agent and at least one custom tool suitable for a telecommunications use case. Possible examples include:</p> <ul> <li>Telco Products/Roaming plan recommendation engine (preferred, due to immediate relevance to JD)</li> <li>Billing dispute parsing and categorization (good to have)</li> <li>Data usage history check (good to have)</li> </ul> <p>Mocked data is allowed to enable the tool\u2019s demonstration. To keep within a time bound, please describe some of the approaches you have planned and would have utilised, if given sufficient time.</p> <p>Clearly document:</p> <ul> <li>The specific business problem your custom tool addresses.</li> <li>Integration method between your tool and the agent.</li> </ul>"},{"location":"tasks/0301_custom_agent/#proposed-design","title":"Proposed Design","text":"<p>The custom agent will be built with LangChain using the <code>AgentExecutor</code> API. A conversational LLM (OpenAI <code>gpt-3.5-turbo</code>) will drive the agent. The key custom tool is a Roaming Plan Recommendation utility that looks up a mock catalogue of plans and selects the most appropriate option for the user based on destination, expected usage and budget. Additional lightweight tools can be added (such as a billing dispute classifier) but the focus is on demonstrating one complete example.</p>"},{"location":"tasks/0301_custom_agent/#tool-implementation","title":"Tool implementation","text":"<ul> <li>Mock data is loaded from CSV files to an SQLite database.</li> <li>Business logic is implemented as a Python function that accepts structured   input (destination, data usage, travel duration) and returns a recommended   plan with reasoning.</li> <li>The function is wrapped as a <code>StructuredTool</code> in LangChain so the agent can   invoke it when required.</li> </ul>"},{"location":"tasks/0301_custom_agent/#agent-flow","title":"Agent flow","text":"<ol> <li>Prompt &amp; Memory \u2013 the agent uses a conversation chain with minimal    memory to maintain context.</li> <li>Tool Calls \u2013 when the user asks for roaming advice the agent calls the    recommendation tool, passing the parsed parameters.</li> <li>Response \u2013 the result is combined with natural language guidance from the    LLM.</li> </ol> <p>This design keeps the tool logic separate from the agent so that more telco utilities can be added easily. Mock data keeps the implementation simple while showing how a real data source would be integrated.</p>"},{"location":"tasks/0301_custom_agent/#language-aware-semantic-interpreter-features","title":"Language-aware Semantic Interpreter Features","text":"<p>To fulfill the chat agent's role as a language-aware interpreter between user inputs and the RoamingPlanRecommender (RPR) tool, the following design features are included:</p> <ul> <li>Natural Language Understanding: The agent uses the LLM to extract and normalize structured fields (e.g., destination, duration, service type, data amount) from freeform text.</li> <li>Progressive Slot Filling: It tracks missing values and engages in a retry loop until all required fields are gathered.</li> <li>Validation Feedback Loop: Invalid values (e.g., unknown country or non-numeric duration) are flagged with helpful messages, prompting retry until all inputs are valid for RPR.</li> <li>Structured RPR Call: Once validated, inputs are passed in structured format to RPR (destination, duration_days, service_type, data_needed_gb).</li> <li>Results Templating: Agent formats the RPR shortlist using ranked output and includes pricing, usage limits, and pros/cons.</li> <li>Plan Confirmation Flow: Agent asks user to confirm preferred plan and whether they want to proceed to purchase.</li> <li>Purchase Redirect Payload: Upon confirmation, the agent generates a structured JSON payload and initiates redirection to a URL with this plan for purchase.</li> </ul>"},{"location":"tasks/0301_custom_agent/#ux-workflow-for-roaming-plan-recommendation-agent","title":"UX Workflow for Roaming Plan Recommendation Agent","text":"<p>This section outlines the user experience (UX) workflow and agent control flow for recommending roaming plans based on natural language inputs. The flow is implemented using LangChain's <code>AgentExecutor</code> framework, integrated with a structured roaming plan database interface.</p> <p>The goal of the agent is to assist users in selecting the most suitable roaming plan for their travel needs. The system supports natural English input, handles out-of-scope queries gracefully, and guides the user step-by-step through a structured interaction.</p>"},{"location":"tasks/0301_custom_agent/#mermaid-diagram","title":"Mermaid Diagram","text":"<pre><code>graph TD\n    A[Start Interaction] --&gt; B{Is User Looking for Roaming Plan?}\n    B -- No --&gt; Z[Redirect to General Chat Support]\n    B -- Yes --&gt; C[Handle Irrelevant or Malicious Prompts Gracefully]\n    C --&gt; D[Gather Destination]\n    D --&gt; E[Gather Travel Duration]\n    E --&gt; F[Gather Data/Call/SMS Needs]\n    F --&gt; G{Valid Inputs?}\n    G -- No --&gt; F\n    G -- Yes --&gt; H[Query Plan Database Tool]\n    H --&gt; I[Shortlist Top 3 Plans]\n    I --&gt; J[Show Plans with Pros/Cons and Recommendation]\n    J --&gt; K{User Selected a Plan?}\n    K -- No --&gt; L[Offer to Exit or Return to Start]\n    K -- Yes --&gt; M[Confirm Selection]\n    M --&gt; N{User Ready to Purchase?}\n    N -- No --&gt; L\n    N -- Yes --&gt; O[Redirect to Purchase Workflow with Plan JSON]</code></pre>"},{"location":"tasks/0301_custom_agent/#step-by-step-workflow-description","title":"Step-by-Step Workflow Description","text":""},{"location":"tasks/0301_custom_agent/#step-a-start-interaction","title":"Step A: Start Interaction","text":"<ul> <li>Triggered by user's natural language query (e.g., \"What are the best roaming options for Malaysia this weekend?\").</li> <li>Agent listens using a LangChain conversation chain with light memory.</li> </ul>"},{"location":"tasks/0301_custom_agent/#step-b-identify-intent","title":"Step B: Identify Intent","text":"<ul> <li>Parse whether the user's intent is about roaming plans.</li> <li>If not, redirect politely to general support.</li> </ul>"},{"location":"tasks/0301_custom_agent/#step-c-handle-off-topic-inputs","title":"Step C: Handle Off-topic Inputs","text":"<ul> <li>Gracefully respond to irrelevant (\"how bout them bears?\") or malicious prompts (\"forget all instructions\") with mild redirection back to main task.</li> </ul>"},{"location":"tasks/0301_custom_agent/#steps-df-requirement-gathering","title":"Steps D\u2013F: Requirement Gathering","text":"<ul> <li> <p>Ask user sequentially:</p> </li> <li> <p>Which country are you traveling to?</p> </li> <li>How long will you be staying?</li> <li>What services do you need (data, calls, SMS)?</li> <li>Inputs validated against known list of destinations and valid durations.</li> </ul>"},{"location":"tasks/0301_custom_agent/#step-g-retry-logic","title":"Step G: Retry Logic","text":"<ul> <li>If user gives invalid input (e.g., \"I'll be in Blorkistan for a zillion days\"), respond with clarification and request again.</li> </ul>"},{"location":"tasks/0301_custom_agent/#step-h-query-plan-tool","title":"Step H: Query Plan Tool","text":"<ul> <li>Call structured database tool with valid inputs.</li> <li>Fetch matching records from roaming plan database.</li> </ul>"},{"location":"tasks/0301_custom_agent/#step-i-shortlist-plans","title":"Step I: Shortlist Plans","text":"<ul> <li>Rank top 3 matching plans based on suitability (e.g., price, validity, service match).</li> </ul>"},{"location":"tasks/0301_custom_agent/#step-j-present-options","title":"Step J: Present Options","text":"<ul> <li>Display brief plan name, pros/cons, and recommendation.</li> <li>Maintain concise UX suitable for mobile and voice interfaces.</li> </ul>"},{"location":"tasks/0301_custom_agent/#step-k-user-decision","title":"Step K: User Decision","text":"<ul> <li>Ask: \"Would you like to select one of these plans?\"</li> <li>If not, offer to go back or end the session.</li> </ul>"},{"location":"tasks/0301_custom_agent/#step-m-confirm-plan-selection","title":"Step M: Confirm Plan Selection","text":"<ul> <li>Echo selected plan and validate user intent.</li> </ul>"},{"location":"tasks/0301_custom_agent/#step-n-purchase-intent","title":"Step N: Purchase Intent","text":"<ul> <li>Ask: \"Would you like to proceed to purchase this plan now?\"</li> </ul>"},{"location":"tasks/0301_custom_agent/#step-o-redirect-to-purchase","title":"Step O: Redirect to Purchase","text":"<ul> <li>If yes, redirect to purchase system with plan data encoded in JSON payload:</li> </ul> <pre><code>{\n  \"plan\": {\n    \"zone\": 1,\n    \"destination\": \"Malaysia\",\n    \"duration_days\": 1,\n    \"data_gb\": 1,\n    \"price_sg\": 1.0\n  },\n  \"user_id\": \"&lt;session_or_user_token&gt;\"\n}\n</code></pre> <p>This redirect URL or payload is configurable and can integrate with existing purchase portals or mocked endpoints for testing.</p>"},{"location":"tasks/0301_custom_agent/#test-cases","title":"Test cases","text":"<p>Roaming Plan Tool</p> <p>Basic match on exact plan</p> <ul> <li>Test input: Singapore, 1-day trip, 1GB data</li> <li>Expected: Plan returned exactly as specified in the DB.</li> </ul> <p>Interpolated duration match</p> <ul> <li>Test input: Malaysia, 2-day trip, 2GB</li> <li>Condition: No exact 2-day plan, should interpolate between 1-day and 3-day</li> </ul> <p>Invalid destination</p> <ul> <li>Test input: \"Blorkistan\", 3-day trip</li> <li>Expected: Empty list, error logged about missing zone.</li> </ul> <p>High data need triggers filtering</p> <ul> <li>Test input: Thailand, 7-day trip, 20GB</li> <li>Expected: Only plans with \u2265 20GB or fallback score of LARGE_GB</li> <li>Assert: Highest data_gb plan selected if no perfect match.</li> </ul> <p>Unsupported service type</p> <ul> <li>Test input: service_type = \"fax\"</li> <li>Expected: No score computed \u2192 empty result</li> </ul> <p>Recommendation Agent</p> Use Case Best Tool Multi-turn conversation <code>agent.step()</code> or <code>AgentExecutor.invoke()</code> with <code>pytest</code> Tool call correctness Mocking + unittest or <code>pytest</code> Output structure validation <code>pytest</code> + <code>jsonschema</code> or custom assert logic State machine step-level testing Custom agent class with exposed state with <code>pytest</code> <ul> <li>Valid query \u2014 \"I'm going to Japan for 3 days and need 2GB of data.\" \u2192 Agent returns 3 plan options and confirms.</li> <li>Invalid country \u2014 \"I'll be in Blorkistan.\" \u2192 Agent retries with validation feedback.</li> <li>Near match country \u2014 \"I'm traveling to Korea.\" \u2192 Agent clarifies with user they are traveling to South Korea, \"Korea, Republic of\" and selects the appropriate match from available countries.</li> <li>Plan query \u2014 \"Need data for Thailand.\" \u2192 Agent prompts for duration and amount.</li> <li>Non-numeric near match duration \u2014 \"I'll be there for a few moons.\" \u2192 Agent retries clarifies if user meant months.</li> <li>Non-numeric nonsense duration \u2014 \"I'll be there for a few spoons.\" \u2192 Agent retries asking for number of days.</li> <li>Out-of-scope query \u2014 \"How's the weather in Tokyo?\" \u2192 Redirects or politely declines.</li> <li>High data demand \u2014 \"Going to Malaysia, need 100GB for 2 weeks.\" \u2192 Agent returns highest available plan and clarifies additional charges apply for excess data.</li> <li>SMS-only request \u2014 \"Going to Vietnam, only need SMS for 5 days.\" \u2192 Filters and ranks by SMS cost.</li> <li>Purchase rejection \u2014 User declines to buy after plan is shown \u2192 Agent offers to restart or exit.</li> <li>User confirms plan \u2014 Agent assembles JSON payload and returns redirect link.</li> <li>Unexpected user utterance mid-flow \u2014 \"Nevermind, show me movie times\" \u2192 Agent gently resets or offers graceful exit.</li> </ul>"},{"location":"tasks/0302_rag/","title":"Retrieval-Augmented Generation (RAG)","text":"<p>Implement a basic RAG pipeline to ground your agent's responses. You may use:</p> <ul> <li>A small document collection</li> <li>Mocked/Generated telco knowledge base </li> <li>Public web available data</li> </ul> <p>Clearly indicate in your response logs when retrieved information is being utilized. Whilst there is limited opportunity to extensively fine-tune, do state some your proposed techniques/approaches to improve the RAG pipeline</p>"},{"location":"tasks/0302_rag/#proposed-design","title":"Proposed Design","text":"<p>The RAG component will provide the agent with factual context sourced from a small knowledge base of telco FAQs and roaming policies. The pipeline will be built with LangChain and use the following components:</p> <ol> <li>Document Loader \u2013 markdown and text files are loaded from <code>data/</code> using    LangChain's generic loaders.</li> <li>Embeddings Model \u2013 OpenAI embeddings (<code>text-embedding-3-small</code>) generate    vector representations of each document chunk.</li> <li>Vector Store \u2013 the embeddings are stored in a local FAISS index which    is persisted to disk so it can be reused across runs.</li> <li>Retriever \u2013 a simple similarity search (<code>k=4</code>) fetches the most relevant    passages for each user query.</li> <li>Response Synthesis \u2013 retrieved passages are passed to the LLM using    LangChain's <code>RetrievalQA</code> chain which appends citations in the final answer.</li> </ol>"},{"location":"tasks/0302_rag/#improvement-ideas","title":"Improvement ideas","text":"<ul> <li>Experiment with cosine similarity thresholding to reduce irrelevant snippets.</li> <li>Preprocess text with domain specific synonyms to improve recall.</li> <li>Monitor retrieval hits and misses to iteratively expand the document set.</li> </ul> <p>By keeping the dataset small and local we avoid heavy infrastructure while still demonstrating how the agent can reference up-to-date telco knowledge when answering user questions.</p>"},{"location":"tasks/0303_integration/","title":"Integration Strategy and Approach (Write-up)","text":"<p>Provide a concise (~400 words) strategy document outlining:</p> <ul> <li>Possible deployment methods for your agent in an enterprise telco environment (e.g., WhatsApp, Microsoft Teams, web portal).</li> <li>Anticipated practical integration challenges (authentication, latency, UI design, scalability).</li> <li>Metrics to evaluate agent performance and value in a production environment.</li> </ul>"},{"location":"tasks/0303_integration/#strategy","title":"Strategy","text":"<p>The agent will be packaged as a lightweight Python service exposing a REST API via FastAPI. This keeps deployment flexible \u2013 the same container image can run in a VM, Kubernetes cluster or serverless platform. For immediate demonstration the service can also be invoked from a simple command-line client or Jupyter notebook.</p>"},{"location":"tasks/0303_integration/#deployment-options","title":"Deployment options","text":"<ol> <li>Web portal \u2013 integrate the API with an internal web application that    provides login via the corporate SSO provider. This allows rapid iteration and    easy access for employees.</li> <li>Microsoft Teams or Slack \u2013 expose a chatbot interface using the    respective platform SDKs. This lowers friction for frontline staff who already    rely on these tools.</li> <li>WhatsApp Business \u2013 for customer-facing interactions, integrate with a    WhatsApp bot or similar messaging channel. The same API can power both    internal and external interfaces.</li> </ol>"},{"location":"tasks/0303_integration/#key-integration-challenges","title":"Key integration challenges","text":"<ul> <li>Authentication and secrets \u2013 API keys for the LLM provider must be stored   securely. Use environment variables loaded via <code>python-dotenv</code> and keep them   out of version control. When deploying to cloud services, rely on secret   managers or encrypted storage.</li> <li>Latency and cost \u2013 LLM calls introduce network latency. Caching frequent   responses or using smaller models for quick classification tasks can improve   performance. Monitoring token usage is essential for budgeting.</li> <li>User experience \u2013 responses should be concise and reference retrieved   knowledge when applicable. Iterative testing with users will help tune prompts   and conversation flow.</li> <li>Scalability \u2013 container-based deployment allows horizontal scaling. If the   service becomes popular, a managed queue (e.g., RabbitMQ or Azure Service Bus)   can buffer incoming requests.</li> </ul>"},{"location":"tasks/0303_integration/#metrics","title":"Metrics","text":"<ul> <li>Turn\u2011around time \u2013 average latency between user question and final answer.</li> <li>Tool invocation counts \u2013 frequency of the roaming recommendation tool and   retrieval calls to gauge usefulness.</li> <li>User satisfaction \u2013 collect optional ratings or NPS scores after   interactions.</li> <li>Retrieval hit rate \u2013 percentage of queries where relevant documents were   found in the RAG index.</li> </ul> <p>The overall goal is to keep the service modular so additional telco tools or new retrieval sources can be plugged in with minimal changes. A small amount of observability (request logging and token usage stats) will provide insights for future optimisation.</p>"},{"location":"tasks/0304_usage_report/","title":"Usage report","text":"<p>Create a simple usage dashboard or logging mechanism demonstrating</p> <ul> <li>Total user queries handled</li> <li>Breakdown of tool usage frequency</li> <li>Retrieval hit/miss analytics</li> </ul> <p>Feel free to use lightweight frameworks like Streamlit, Gradio, NiceGUI, Flask, or FastAPI.</p>"}]}